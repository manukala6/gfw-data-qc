{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Tree Cover Loss QC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supported `gfw-data-api` contextual layers:\n",
    "    - birdlife_key_biodiversity_areas\n",
    "    - birdlife_alliance_for_zero_extinction_sites\n",
    "    - wdpa_protected_areas\n",
    "    - gfw_mining_concessions\n",
    "    - gmw_global_mangrove_extent_2016\n",
    "    - rspo_oil_palm\n",
    "    - gfw_oil_palm\n",
    "    - idn_forest_moratorium\n",
    "    - wwf_tiger_conservation_landscapes\n",
    "    - gfw_wood_fiber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import fiona\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "from utils import parse_bounds, concatenate_windows\n",
    "from tqdm.notebook import tqdm\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterstats import zonal_stats\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data config\n",
    "DATA_DIR = 'admin_areas'\n",
    "OUT_DIR = 'output'\n",
    "SHP_FN = 'sumatera_barat.shp'\n",
    "treecover_threshold = 30\n",
    "contextual_layers = [\n",
    "    #'idn_forest_moratorium',\n",
    "    'wdpa_protected_areas'\n",
    "]\n",
    "\n",
    "shp_fp = os.path.join(DATA_DIR, SHP_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directories\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.mkdir(OUT_DIR)\n",
    "\n",
    "if not os.path.exists('tmp'):\n",
    "    os.mkdir('tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get admin area bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use bounds to read a window containing the admin zone from raster tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98.59667969, -3.35000229, 101.89291382, 0.90738916)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with fiona.open(shp_fp) as src:\n",
    "    bounds = src.bounds\n",
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['090E', '100E'], ['00N', '10N'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list, Y_list = parse_bounds(bounds)\n",
    "X_list, Y_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intersect admin area with contextual layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s3_asset_uri(dataset):\n",
    "    if dataset == 'wdpa_protected_areas':\n",
    "        res = requests.get(f'https://data-api.globalforestwatch.org/dataset/{dataset}/latest/assets?asset_type=Geopackage')\n",
    "    else:\n",
    "        res = requests.get(f'https://data-api.globalforestwatch.org/dataset/{dataset}/latest/assets?asset_type=ESRI Shapefile')\n",
    "    return res.json()['data'][0]['asset_uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intersect_layers(layers, bounds, shp_fp):\n",
    "    \n",
    "    # return dissolved shapefile if there are no contextual layers\n",
    "    if len(contextual_layers) == 0:\n",
    "        adm_shp = gpd.read_file(shp_fp)\n",
    "        dissolved = gpd.GeoSeries(adm_shp.geometry).unary_union\n",
    "        dissolved_gs = gpd.GeoSeries(dissolved)\n",
    "        dissolved_gs.to_file(os.path.join('tmp', 'dissolved_intersection.shp'))\n",
    "        \n",
    "        return dissolved\n",
    "    \n",
    "    # parse for s3 paths\n",
    "    s3_paths = [get_s3_asset_uri(layer) for layer in layers]\n",
    "    \n",
    "    # read contextual layers within bounds of admin area\n",
    "    contextual_gdfs = []\n",
    "    for s3_path in s3_paths:\n",
    "        if s3_path[-4:] == '.zip':\n",
    "            filename=f'zip+{s3_path}'\n",
    "        else:\n",
    "            filename=s3_path\n",
    "        gdf = gpd.read_file(\n",
    "            filename=filename,\n",
    "            bbox=bounds,\n",
    "        )\n",
    "        contextual_gdfs.append(gdf)\n",
    "    \n",
    "    # intersect all layers\n",
    "    intersected_gdf = gpd.read_file(shp_fp)\n",
    "    for contextual_gdf in contextual_gdfs:\n",
    "        try:\n",
    "            intersected_gdf = gpd.overlay(intersected_gdf, contextual_gdf, how='intersection')\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # dissolve and save to tmp\n",
    "    dissolved = gpd.GeoSeries(intersected_gdf.geometry).unary_union\n",
    "    dissolved_gs = gpd.GeoSeries(dissolved)\n",
    "    dissolved_gs.to_file(os.path.join('tmp', 'dissolved_intersection.shp'))\n",
    "    \n",
    "    return dissolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mnukala.local/.conda/envs/automated-qc/lib/python3.9/site-packages/geopandas/geodataframe.py:577: RuntimeWarning: Sequential read of iterator was interrupted. Resetting iterator. This can negatively impact the performance.\n",
      "  for feature in features_lst:\n"
     ]
    }
   ],
   "source": [
    "intersection = intersect_layers(contextual_layers, bounds, shp_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold tree cover density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate binary mask array from the tree cover density tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcd_arrs = []\n",
    "for Y in Y_list:\n",
    "    for X in X_list:\n",
    "        with rio.open(f's3://gfw-data-lake/umd_tree_cover_density_2000/v1.6/raster/epsg-4326/10/40000/percent/geotiff/{Y}_{X}.tif') as src:\n",
    "            window = from_bounds(\n",
    "                bounds[0],\n",
    "                bounds[1],\n",
    "                bounds[2],\n",
    "                bounds[3],\n",
    "                src.transform\n",
    "            )\n",
    "            tcd_arrs.append(src.read(1, window=window))\n",
    "            win_affine = src.window_transform(window)\n",
    "            \n",
    "            print(f'Extracted window for {Y}, {X}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcd_arr = concatenate_windows(tcd_arrs, X_list, Y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tcd_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reclassify using binary threshold\n",
    "tcd_arr_mask = tcd_arr.copy()\n",
    "tcd_arr_mask[np.where( tcd_arr <= treecover_threshold )] = 0\n",
    "tcd_arr_mask[np.where( tcd_arr > treecover_threshold )] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tcd_arr_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set area array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read area array and mask by tree cover density threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_arrs = []\n",
    "for Y in Y_list:\n",
    "    for X in X_list:\n",
    "        with rio.open(f's3://gfw-files/2018_update/area/{Y}_{X}.tif') as src:\n",
    "            area_arr = src.read(1, window=from_bounds(\n",
    "                bounds[0],\n",
    "                bounds[1],\n",
    "                bounds[2],\n",
    "                bounds[3],\n",
    "                src.transform\n",
    "            ))\n",
    "        area_arrs.append(area_arr)\n",
    "        \n",
    "        print(f'Extracted window for {Y}, {X}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_arr = concatenate_windows(area_arrs, X_list, Y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(area_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask by treecover threshold array\n",
    "area_mask = np.multiply(tcd_arr_mask, area_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(area_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mask tree cover loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read tree cover loss from window and mask using tree cover density threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read as np array from bounds\n",
    "tcl_arrs = []\n",
    "for Y in Y_list:\n",
    "    for X in X_list:\n",
    "        with rio.open(f's3://gfw-data-lake/umd_tree_cover_loss/v1.7/raster/epsg-4326/10/40000/year/geotiff/{Y}_{X}.tif') as src:\n",
    "            tcl_arr = src.read(1, window=from_bounds(\n",
    "                bounds[0],\n",
    "                bounds[1],\n",
    "                bounds[2],\n",
    "                bounds[3],\n",
    "                src.transform\n",
    "        ))\n",
    "        \n",
    "        tcl_arrs.append(tcl_arr)\n",
    "        print(f'Extracted window for tree cover loss tile: {Y}, {X}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcl_arr = concatenate_windows(tcl_arrs, X_list, Y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tcl_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask tree cover loss by treecover threshold\n",
    "tcl_masked = np.multiply(tcd_arr_mask, tcl_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tcl_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute zonal statistics for admin boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_by_year_ha = {}\n",
    "\n",
    "for year in tqdm(range(1,20)):\n",
    "    \n",
    "    # copy thresholded tree cover loss array\n",
    "    tcl_arr_year = tcl_masked.copy()\n",
    "    \n",
    "    # mask by current year\n",
    "    tcl_arr_year[np.where( tcl_masked != year )] = 0\n",
    "    tcl_arr_year[np.where( tcl_masked == year )] = 1\n",
    "    \n",
    "    # convert to ha using area mask\n",
    "    tcl_arr_year_area = np.multiply(area_mask, tcl_arr_year) / 10000\n",
    "    \n",
    "    # compute zonal stats for admin area\n",
    "    zstats = zonal_stats(\n",
    "        os.path.join('tmp', 'dissolved_intersection.shp'),\n",
    "        tcl_arr_year_area,\n",
    "        stats='sum',\n",
    "        affine=win_affine,\n",
    "        all_touched=False,\n",
    "        nodata=-999\n",
    "    )\n",
    "    \n",
    "    # log\n",
    "    annual_loss = zstats[0]['sum']\n",
    "    print(f'TCL in {year + 2000}: {int(annual_loss)} ha')\n",
    "    loss_by_year_ha[year + 2000] = annual_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame.from_dict(loss_by_year_ha, orient='index')\n",
    "loss_df = loss_df.rename(columns={0:'area_ha'})\n",
    "loss_df['threshold'] = f'{treecover_threshold}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df.to_csv(os.path.join(\n",
    "    OUT_DIR, \n",
    "    f'{SHP_FN[:-4]}_tree_cover_loss_ha.csv'),\n",
    "    index_label='year'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
